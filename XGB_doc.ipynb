{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score\n",
        "from yellowbrick.regressor import prediction_error\n",
        "print(\"Make sure to install shap as: !pip install shap\")\n",
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "mjsMKbs8wfK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for shap installed\n",
        "stream = os.popen('pip list')\n",
        "\n",
        "pip_list = stream.read()\n",
        "\n",
        "Package=list(pip_list.split(\" \"))\n",
        "# Count variable\n",
        "c = 0\n",
        "for i in Package:\n",
        "    if \"shap\" in i:\n",
        "        c = 1\n",
        "\n",
        "# Checking the value of c\n",
        "if c==1:\n",
        "  print(\"Shap Installed\")\n",
        "else :\n",
        "  print(\"Shap is not installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-khxPqxo-0c",
        "outputId": "a170d1e6-6405-455d-c810-e8f096d84f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shap Installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Constructing paths based on zone and resolution\n",
        "home = input(\"Enter the home directory where the datasets are located (example:/content/ARM_ERA_12)\")\n",
        "\n",
        "# Asking the user for the resolution of the dataset\n",
        "resolution = [input(\"Enter the name/resolution of the dataset(example: 1000m ): \")]\n",
        "\n",
        "#1000m_dataV1_train.csv\n",
        "# Asking for the name of the training dataset and constructing the full path\n",
        "train_dataset_name = input(\"Enter the name of the training dataset (including file extension - example: 1000m_dataV1_train.csv): \")\n",
        "train_file = home + '/' + train_dataset_name\n",
        "\n",
        "# Checking if the training file exists and prompting the user until a valid file is provided\n",
        "while not os.path.exists(train_file):\n",
        "    print(\"The specified training file does not exist. Please enter the correct dataset  with the correct format.\")\n",
        "    train_dataset_name = input(\"Enter the name of the training dataset (including file extension): \")\n",
        "    train_file = home + '/' + train_dataset_name\n",
        "\n"
      ],
      "metadata": {
        "id": "6kj3EFnqojGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb2a832-cc30-4435-b1e2-f4a41c63080c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the home directory where the datasets are located (example:/content/ARM_ERA_12)/content/Airmoss\n",
            "Enter the name/resolution of the dataset(example: 1000m ): 1400m\n",
            "Enter the name of the training dataset (including file extension - example: 1000m_dataV1_train.csv): A4_1400m_processed_train.csv\n",
            "The specified training file does not exist. Please enter the correct dataset  with the correct format.\n",
            "Enter the name of the training dataset (including file extension): A4_1400m_processed__train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#_dataV1_test.csv\n",
        "# Asking for the name of the testing dataset and constructing the full path\n",
        "test_dataset_name = input(\"Enter the name of the testing dataset (including file extension - example: 1000m_dataV1_test.csv): \")\n",
        "test_file = home + '/' + test_dataset_name\n",
        "\n",
        "# Checking if the testing file exists and prompting the user until a valid file is provided\n",
        "while not os.path.exists(test_file):\n",
        "    print(\"The specified testing file does not exist. Please enter the correct dataset name with the correct format.\")\n",
        "    test_dataset_name = input(\"Enter the name of the testing dataset (including file extension - example: 1000m_dataV1_test.csv): \")\n",
        "    test_file = home + '/' + test_dataset_name"
      ],
      "metadata": {
        "id": "1DL5n5KLpBrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf391f20-666f-4604-c638-1115fb6f622f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the testing dataset (including file extension - example: 1000m_dataV1_test.csv): A4_1400m_processed_test.csv\n",
            "The specified testing file does not exist. Please enter the correct dataset name with the correct format.\n",
            "Enter the name of the testing dataset (including file extension - example: 1000m_dataV1_test.csv): A4_1400m_processed__test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading training data\n",
        "train_data = pd.read_csv(train_file,\n",
        "                         usecols=['SMERGE', 'Date', 'Temp', 'PageName', 'LAI', 'Albedo', 'NDVI', 'Clay', 'Sand', 'Silt',\n",
        "                                  'Slope', 'Elevation', 'Ascept'])\n",
        "\n",
        "train_page = train_data['PageName']\n",
        "train_date = train_data['Date']\n"
      ],
      "metadata": {
        "id": "t0lasi2owHVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading test data\n",
        "test_data = pd.read_csv(test_file,\n",
        "                        usecols=['SMERGE', 'Date', 'Temp', 'PageName', 'LAI', 'Albedo', 'NDVI', 'Clay', 'Sand', 'Silt',\n",
        "                                 'Slope', 'Elevation', 'Ascept'])\n",
        "test_page = test_data[['PageName']]\n",
        "test_ndvi = test_data['NDVI']\n",
        "test_dates = test_data['Date']\n"
      ],
      "metadata": {
        "id": "2TplN0QCwJ0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing 'Date' column for training and testing\n",
        "train_data['Date'] = pd.to_datetime(train_data['Date'], format=\"%m/%d/%Y\").astype(int)\n",
        "test_data['Date'] = pd.to_datetime(test_data['Date'], format=\"%m/%d/%Y\").astype(int)"
      ],
      "metadata": {
        "id": "AjC2XYda_Leg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separating target data and variables\n",
        "y_train = train_data['SMERGE']\n",
        "x_train = train_data[\n",
        "    ['Clay', 'Sand', 'Silt', 'Elevation', 'Ascept', 'Slope', 'NDVI', 'Date', 'LAI', 'Albedo', 'Temp']]\n",
        "print(train_data)"
      ],
      "metadata": {
        "id": "JNkCLb7G_SO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separating target data and variables\n",
        "y_test = test_data['SMERGE']\n",
        "x_test = test_data[\n",
        "    ['Clay', 'Sand', 'Silt', 'Elevation', 'Ascept', 'Slope', 'NDVI', 'Date', 'LAI', 'Albedo', 'Temp']]\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "o5fLDge6_PXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the XGBoost model\n",
        "model = XGBRegressor(verbosity=1,n_estimators=500,max_depth=10,tree_method='gpu_hist')\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# Compiling and training the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predicting and evaluating the model with the trained model\n",
        "h = model.predict(x_test)\n",
        "accuracy = model.score(x_test, y_test)\n",
        "print('Accuracy:', accuracy)\n",
        "MSE = mse(y_test, h)\n",
        "RMSE = np.sqrt(MSE)\n",
        "R_squared = r2_score(y_test, h)\n",
        "print(\"\\nRMSE: \", np.round(RMSE, 2))\n",
        "print()\n",
        "print(\"R-Squared: \", np.round(R_squared, 2))\n",
        "\n",
        "# Preparing the output dataframe\n",
        "test_data['Date'] = test_dates\n",
        "test_data['ML_'] = h\n",
        "test_data['PageName'] = test_page\n",
        "test_data = test_data[[\"Clay\",\"Sand\",\"Elevation\",\"Ascept\",\"NDVI\",\"Date\",\"LAI\",\"Albedo\",\"PageName\",\"SMERGE\",\"ML_\"]]\n",
        "\n",
        "# Making the Prediction Error Plot\n",
        "print(\"\\nPrediction Error Plot\")\n",
        "error_plot = prediction_error(model, x_train, y_train, x_test, y_test)\n",
        "print(error_plot)\n",
        "\n",
        "# Saving the output dataframe to a CSV file\n",
        "test_data.to_csv( home + resolution[0] + \".csv\")\n",
        "\n",
        "# Generating variable importance plots\n",
        "x_sampled = x_train.sample(1000, random_state=10)\n",
        "explainer = shap.Explainer(model, x_sampled)\n",
        "shap_values = explainer(x_sampled)\n",
        "shap.plots.bar(shap_values, max_display = 11)\n",
        "save_shap = input(\"Would you like to save the variable importance plot?: y/n\")\n",
        "if save_shap == 'y':\n",
        "#Saving varibale importance plot\n",
        "  mean_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "  shap_pd = pd.DataFrame(mean_shap, index = x_sampled.columns).sort_values(by=[0],ascending = False)\n",
        "  shap_pd.to_csv(home + resolution[0] + '_SHAP.csv')"
      ],
      "metadata": {
        "id": "hZJ5kmQywTGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J716PVrF8_sn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}