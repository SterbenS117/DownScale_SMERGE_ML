{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAVnBMYj-fq0"
      },
      "outputs": [],
      "source": [
        "import arcpy\n",
        "from arcpy import env\n",
        "import re\n",
        "import pandas as pd\n",
        "from arcpy.sa import *\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def raster_points(input_raster, output_raster):\n",
        "    # Read the input and check rasters\n",
        "    in_raster = Raster(input_raster)\n",
        "    ExtractMultiValuesToPoints(thirty_points, [[in_raster, output_raster]])"
      ],
      "metadata": {
        "id": "eAH0v1ZaI_Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parent folder and the geodatabase name\n",
        "parent_folder = os.path.dirname(__file__)\n",
        "geodatabase_name = \"example.gdb\""
      ],
      "metadata": {
        "id": "g6l8OLk6-15M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the file geodatabase\n",
        "geodatabase_path = os.path.join(parent_folder, geodatabase_name)\n",
        "#arcpy.CreateFileGDB_management(parent_folder, geodatabase_name)"
      ],
      "metadata": {
        "id": "4eW-z5_q-1-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the geodatabase as the workspace\n",
        "arcpy.env.workspace = geodatabase_path"
      ],
      "metadata": {
        "id": "jms9Nvmn-2D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the environment\n",
        "arcpy.env.parallelProcessingFactor = 0\n",
        "arcpy.CheckOutExtension(\"Spatial\")\n",
        "arcpy.env.matchMultidimensionalVariable = False\n",
        "arcpy.env.overwriteOutput = True"
      ],
      "metadata": {
        "id": "rjp02L8M-2Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data product name\n",
        "product = input(\"Enter the name of the data product: \")"
      ],
      "metadata": {
        "id": "zQ8dMOSx-2O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the input directory\n",
        "input_dir = input(\"Enter the input directory: \")"
      ],
      "metadata": {
        "id": "0s0vnZZmCJEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the output directory\n",
        "output_dir = input(\"Enter the output directory: \")"
      ],
      "metadata": {
        "id": "USqzZdd4CJI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read list of dates\n",
        "text_file = open(\"dates.txt\", \"r\")\n",
        "\n",
        "while not os.path.exists(text_file):\n",
        "    print('The date list txt was not found, should be in the same directory as the .py script')\n",
        "    n = input(\"Press enter to try again\")\n",
        "    text_file = open(\"dates.txt\", \"r\")\n",
        "date = text_file.read().split(',')"
      ],
      "metadata": {
        "id": "Js0TRjmCDN62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_shape_file = input(\"Enter the full file path and name of the grid shape file: \")\n",
        "\n",
        "while not os.path.exists(grid_shape_file):\n",
        "    print('The shapefile was not found, should be in the same directory as the .py script')\n",
        "    co = input(\"Please try again: \")"
      ],
      "metadata": {
        "id": "uGgvMHw5EF-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_shape_file = input(\"Enter the full file path and name of the point shape file that you wish to generate: \")\n",
        "point_check = input(\"Enter Y if you are adding to an existing point shape file, if you are creating/overwrite a new point file enter N\")\n",
        "\n",
        "while not point_check != 'Y' and point_check != 'N':\n",
        "    point_shape_file = input(\"Please try again: \")\n",
        "\n",
        "\n",
        "if point_check == 'Y':\n",
        "    while not os.path.exists(point_shape_file):\n",
        "        print('The shapefile was not found, should be in the same directory as the .py script')\n",
        "        point_shape_file = input(\"Please try again: \")\n",
        "\n",
        "thirty_grids = grid_shape_file\n",
        "thirty_points = point_shape_file\n",
        "\n",
        "if point_check == 'N':\n",
        "    arcpy.management.FeatureToPoint(thirty_grids, thirty_points, \"CENTROID\")"
      ],
      "metadata": {
        "id": "2o9dQ9TeEyru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for d in date:\n",
        "    j = False\n",
        "    date_n = pd.to_datetime(d, format=\"%m/%d/%Y\") + pd.DateOffset(months=1)\n",
        "    year = date_n.year\n",
        "    month = date_n.month\n",
        "    day = date_n.day\n",
        "    doy = date_n.timetuple().tm_yday\n",
        "    for f in os.listdir(input_dir):\n",
        "        if j == True:\n",
        "            break\n",
        "        #try and except is ment to account for the different MDR_layer_extractors\n",
        "        try:# MDR_layer_extractorV1 complient\n",
        "            file_p = f.split('.')\n",
        "            date_c = str(year) + str(doy).zfill(3)\n",
        "            file_p = re.sub(\"\\D\", \"\", file_p[1])\n",
        "            date_p = pd.to_datetime(file_p, format=\"%Y%j\")\n",
        "        except: # MDR_layer_extractorV2 complient\n",
        "            file_p = f.split('.')\n",
        "            date_c = str(year) + str(doy).zfill(3)\n",
        "            file_p = re.sub(\"\\D\", \"\", file_p[0])\n",
        "            date_p = pd.to_datetime(file_p, format=\"%Y%j\")\n",
        "\n",
        "        #print(date_c)\n",
        "        if f.endswith(\".tif\") and date_p.year == year and (int(date_c)-4 <= int(file_p) and int(file_p) <= int(date_c)+4):\n",
        "            input_raster = os.path.join(input_dir, f)\n",
        "            #Has to by date index number, because the arcpy multiopoint function has a name lenght limit\n",
        "            data_name = product+\"_\"+ str(i).zfill(3)\n",
        "            print(data_name + \" \" + date_c)\n",
        "            output_raster = data_name\n",
        "            raster_points(input_raster, output_raster)\n",
        "            j = True\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "5z8PbjwIFion"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}